# Application Architecture Overview

This document provides a high-level overview of the ADHD Cleaning Companion application architecture.

## Core Components and Flow

The application is structured around a few key areas:

1.  **`App.tsx` (Main Orchestrator):**
    *   This is the central component that manages the overall application state, screen navigation, and user interactions.
    *   It handles the API key, loading/error states, and settings like voice and gamification.
    *   It orchestrates the flow of:
        *   Image uploading by the user.
        *   Calling `geminiService.ts` for image analysis and task plan generation.
        *   Managing the list of tasks (creation, completion, reordering).
        *   Providing voice feedback via browser speech synthesis.

2.  **`services/geminiService.ts` (AI Interaction Layer):**
    *   This service is responsible for all communication with the Google Gemini AI.
    *   It contains functions to:
        *   Analyze uploaded images (`analyzeImageWithGemini`): Takes image data, sends it to Gemini using a specific prompt (see `INITIAL_ANALYSIS_PROMPT` in `constants.ts`) expecting JSON output of observations.
        *   Generate cleaning plans (`generateCleaningPlanWithGemini`): Takes the AI's observations, sends them to Gemini using another prompt (see `TASK_GENERATION_PROMPT_TEMPLATE` in `constants.ts`) expecting a JSON list of tasks.
        *   Generate celebratory messages (`generateCelebratoryMessageForTask`): Takes completed task text and asks Gemini for a positive message.
    *   It includes robust JSON parsing (`parseJsonFromGeminiResponse`) to handle AI responses, including those wrapped in markdown code fences, and provides fallbacks.

3.  **`components/` (UI Elements):**
    *   This directory contains various React components responsible for the application's UI.
    *   Key components include:
        *   `ImageUploader.tsx`: Allows users to select and upload images.
        *   `TaskList.tsx`: Displays the list of tasks, handles task completion and reordering.
        *   `AudioVisualizer.tsx`: Provides visual feedback for microphone input and speech output.
        *   `LandingPage.tsx`: The initial screen of the application.
        *   Other supporting UI components like `Header.tsx`, `Footer.tsx`, `LoadingSpinner.tsx`, etc.

4.  **`services/agents/` (Extensible Agent System - Future Potential):**
    *   This system allows for modular "agents" that can analyze context and provide recommendations or actions.
    *   `AgentTypes.ts`: Defines the core interfaces (`AgentContext`, `AgentResponse`, `AgentConfig`) and the `BaseAgent` abstract class.
    *   `AgentOrchestrator.ts`: Manages the registration, activation, and querying of these agents.
    *   Specific agent implementations (e.g., `FocusAgent.ts`, `TaskBreakdownAgent.ts`) provide specialized assistance.
    *   *Currently, this system is not deeply integrated into the main image-to-task flow but demonstrates a pattern for future expansion of AI-driven assistance beyond the primary cleaning tool.*

## Data Flow: Image to Tasks

1.  User uploads one or more images via `ImageUploader.tsx`.
2.  `App.tsx` receives the image data.
3.  `App.tsx` calls `analyzeImageWithGemini` from `geminiService.ts`.
4.  `geminiService.ts` sends images and the `INITIAL_ANALYSIS_PROMPT` to Gemini.
5.  Gemini returns observations (hopefully as JSON).
6.  `geminiService.ts` parses the response.
7.  `App.tsx` receives the observations.
8.  `App.tsx` calls `generateCleaningPlanWithGemini` with these observations.
9.  `geminiService.ts` sends observations and the `TASK_GENERATION_PROMPT_TEMPLATE` to Gemini.
10. Gemini returns a task plan (hopefully as JSON).
11. `geminiService.ts` parses this response.
12. `App.tsx` receives the task list, updates its state, and displays them via `TaskList.tsx`.

## Task Text Convention

*   Task text generated by the AI or added manually may sometimes use an "@" symbol to denote additional context, often a location or a specific sub-area related to the task.
*   For display purposes (e.g., speaking tasks or showing them in a concise UI element), the application often uses only the part of the text *before* the first "@" symbol.
*   This is handled by the `getDisplayTaskText` utility function in `components/utils.ts`.
*   When sending task text back to the AI (e.g., for generating celebration messages), the *full task text* is sometimes used to give the AI more context, though the prompt for celebration messages specifically uses the pre-"@" part.

This architecture aims for a separation of concerns, with UI, AI interaction, and state management handled by distinct parts of the application.
